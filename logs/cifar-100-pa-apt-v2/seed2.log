Namespace(dataset='CIFAR100', first_split_size=10, other_split_size=10, schedule_type='cosine', optimizer='Adam', momentum=0.9, weight_decay=0, model_type='zoo', model_name='vit_pt_imnet', max_task=-1, dataroot='data', workers=4, validation=False, train_aug=True, rand_split=True, k_patches=2, alpha_cls=0.7, alpha_patch=0.5, use_layer_wise=True, gpuid=[0], log_dir='./checkpoints/cifar-100-pa-apt-v2/seed2', learner_type='pa_apt_v2', learner_name='PA_APT_V2_Learner', debug_mode=0, repeat=1, overwrite=0, oracle_flag=False, upper_bound_flag=False, memory=0, temp=2.0, DW=False, prompt_param=['1', '1', '1'], seed=2, batch_size=64, lr=0.004, ema_coeff=0.7, schedule=30, config='configs/cifar-100_pa_apt_v2.yaml')
************************************
* STARTING TRIAL 1
************************************
=============================================
Shuffling....seed is 2
pre-shuffle:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
post-shuffle:[0, 76, 61, 63, 1, 71, 2, 6, 16, 19, 13, 24, 49, 12, 75, 9, 83, 72, 5, 41, 99, 45, 89, 53, 79, 18, 52, 92, 14, 42, 68, 44, 38, 84, 36, 17, 31, 15, 70, 88, 25, 97, 51, 73, 66, 37, 78, 33, 80, 26, 82, 28, 60, 35, 43, 57, 23, 58, 91, 8, 62, 93, 98, 86, 29, 30, 22, 95, 67, 54, 48, 40, 59, 96, 3, 87, 34, 64, 56, 69, 47, 65, 50, 81, 55, 20, 74, 4, 90, 27, 77, 32, 39, 85, 94, 21, 46, 10, 11, 7]
=============================================
Files already downloaded and verified
*****************************************
====================== 1 =======================
Incremental class: Old valid output dimension: 0
Incremental class: New Valid output dimension: 10
/root/miniconda3/envs/apt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Overwriting ...
/root/dl_project/Additive-Prompt-Tuning/learners/default.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_dict = torch.load(filename + 'class.pth')
Optimizer is reset!
*****************************************
LR: 0.004
Epoch:1/30
 * Loss 0.550 | Train Acc 82.151
LR: 0.004
Epoch:2/30
 * Loss 0.301 | Train Acc 90.565
LR: 0.003994250367686589
Epoch:3/30
 * Loss 0.284 | Train Acc 90.925
LR: 0.003977017999882228
Epoch:4/30
 * Loss 0.255 | Train Acc 91.927
LR: 0.0039483524364762965
Epoch:5/30
 * Loss 0.234 | Train Acc 92.989
LR: 0.003908336085693616
Epoch:6/30
 * Loss 0.218 | Train Acc 93.189
LR: 0.00385708398718595
Epoch:7/30
 * Loss 0.212 | Train Acc 93.349
LR: 0.003794743481314153
Epoch:8/30
 * Loss 0.204 | Train Acc 93.289
LR: 0.003721493785571721
Epoch:9/30
 * Loss 0.214 | Train Acc 93.550
LR: 0.00363754547936745
Epoch:10/30
 * Loss 0.221 | Train Acc 93.269
LR: 0.003543139898648343
Epoch:11/30
 * Loss 0.203 | Train Acc 93.450
LR: 0.003438548442103134
Epoch:12/30
 * Loss 0.207 | Train Acc 93.570
LR: 0.0033240717909409543
Epoch:13/30
 * Loss 0.195 | Train Acc 93.950
LR: 0.003200039044488128
Epoch:14/30
 * Loss 0.191 | Train Acc 94.211
LR: 0.00306680677408812
Epoch:15/30
 * Loss 0.183 | Train Acc 94.311
LR: 0.0029247579980244704
Epoch:16/30
 * Loss 0.191 | Train Acc 94.010
LR: 0.0027743010804136474
Epoch:17/30
 * Loss 0.173 | Train Acc 94.631
LR: 0.0026158685572332855
Epoch:18/30
 * Loss 0.187 | Train Acc 93.870
LR: 0.0024499158928607727
Epoch:19/30
 * Loss 0.195 | Train Acc 93.810
LR: 0.0022769201706968945
Epoch:20/30
 * Loss 0.168 | Train Acc 94.892
LR: 0.0020973787216387683
Epoch:21/30
 * Loss 0.179 | Train Acc 94.792
LR: 0.0019118076943449456
Epoch:22/30
 * Loss 0.174 | Train Acc 94.671
LR: 0.0017207405714029067
Epoch:23/30
 * Loss 0.171 | Train Acc 94.351
LR: 0.0015247266356647002
Epoch:24/30
 * Loss 0.160 | Train Acc 94.491
LR: 0.0013243293911597263
Epoch:25/30
 * Loss 0.169 | Train Acc 94.511
LR: 0.0011201249431242457
Epoch:26/30
 * Loss 0.151 | Train Acc 94.992
LR: 0.0009127003418047438
Epoch:27/30
 * Loss 0.159 | Train Acc 95.012
LR: 0.0007026518947963905
Epoch:28/30
 * Loss 0.159 | Train Acc 94.932
LR: 0.0004905834527683376
Epoch:29/30
 * Loss 0.169 | Train Acc 94.411
LR: 0.0002771046735040541
Epoch:30/30
 * Loss 0.153 | Train Acc 95.252
=> Saving class model to: ./checkpoints/cifar-100-pa-apt-v2/seed2/models/repeat-1/task-1/
=> Save Done
validation split name: 1 local = False
 * Val Acc 99.167, Total time 3.20
====================== 2 =======================
Incremental class: Old valid output dimension: 10
Incremental class: New Valid output dimension: 20
Overwriting ...
Optimizer is reset!
*****************************************
LR: 0.004
Epoch:1/30
 * Loss 0.371 | Train Acc 87.680
LR: 0.004
Epoch:2/30
 * Loss 0.241 | Train Acc 92.368
LR: 0.003994250367686589
Epoch:3/30
 * Loss 0.249 | Train Acc 92.067
LR: 0.003977017999882228
Epoch:4/30
 * Loss 0.239 | Train Acc 92.588
LR: 0.0039483524364762965
Epoch:5/30
 * Loss 0.239 | Train Acc 92.428
LR: 0.003908336085693616
Epoch:6/30
 * Loss 0.251 | Train Acc 92.107
LR: 0.00385708398718595
Epoch:7/30
 * Loss 0.229 | Train Acc 92.728
LR: 0.003794743481314153
Epoch:8/30
 * Loss 0.244 | Train Acc 92.508
LR: 0.003721493785571721
Epoch:9/30
 * Loss 0.218 | Train Acc 92.808
LR: 0.00363754547936745
Epoch:10/30
 * Loss 0.211 | Train Acc 93.269
LR: 0.003543139898648343
Epoch:11/30
 * Loss 0.213 | Train Acc 93.429
LR: 0.003438548442103134
Epoch:12/30
 * Loss 0.204 | Train Acc 93.470
LR: 0.0033240717909409543
Epoch:13/30
 * Loss 0.210 | Train Acc 93.450
LR: 0.003200039044488128
Epoch:14/30
 * Loss 0.202 | Train Acc 93.530
LR: 0.00306680677408812
Epoch:15/30
 * Loss 0.196 | Train Acc 93.650
LR: 0.0029247579980244704
Epoch:16/30
 * Loss 0.197 | Train Acc 93.870
LR: 0.0027743010804136474
Epoch:17/30
 * Loss 0.197 | Train Acc 93.870
LR: 0.0026158685572332855
Epoch:18/30
 * Loss 0.200 | Train Acc 93.730
LR: 0.0024499158928607727
Epoch:19/30
 * Loss 0.184 | Train Acc 93.930
LR: 0.0022769201706968945
Epoch:20/30
 * Loss 0.200 | Train Acc 93.590
LR: 0.0020973787216387683
Epoch:21/30
 * Loss 0.187 | Train Acc 93.790
LR: 0.0019118076943449456
